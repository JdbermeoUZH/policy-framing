\begin{tabular}{llllllll}
\toprule
language &                         model\_name &     title & title and first paragraph & title and 5 sentences & title and 10 sentences & title and first sentence each paragraph &  raw text \\
\midrule
      en &            EleutherAI-gpt-neo-1.3B &     0.759 &                     0.792 &                 0.777 &                  0.793 &                                   0.786 &     0.784 \\
      en &            EleutherAI-gpt-neo-125M &     0.686 &                     0.745 &                 0.739 &                  0.748 &                                   0.742 &     0.706 \\
      en &       bert-base-multilingual-cased &     0.715 &                     0.769 &                 0.775 &                  0.748 &                                   0.718 &     0.785 \\
      en & distilbert-base-multilingual-cased &     0.700 &                     0.752 &                 0.779 &                  0.765 &                                   0.757 &     0.772 \\
      en &            facebook-mbart-large-50 &     0.769 &                     0.797 &                 0.812 &                  0.812 &                                   0.778 &     0.777 \\
      en &                               gpt2 &     0.700 &                     0.713 &                 0.702 &                  0.732 &                                   0.719 &     0.731 \\
      en &                  xlm-roberta-large &     0.765 &                     0.805 &             **0.817** &                  0.796 &                                   0.776 &     0.795 \\
      fr &            EleutherAI-gpt-neo-1.3B &     0.547 &                     0.580 &                 0.538 &                  0.536 &                                   0.562 &     0.571 \\
      fr &            EleutherAI-gpt-neo-125M &     0.402 &                     0.462 &                 0.438 &                  0.446 &                                   0.570 &     0.453 \\
      fr &       bert-base-multilingual-cased &     0.536 &                     0.511 &                 0.559 &                  0.527 &                                   0.600 &     0.598 \\
      fr & distilbert-base-multilingual-cased &     0.465 &                     0.471 &                 0.505 &                  0.583 &                               **0.619** &     0.548 \\
      fr &            facebook-mbart-large-50 &     0.536 &                     0.579 &                 0.568 &                  0.553 &                                   0.580 &     0.596 \\
      fr &                               gpt2 &     0.419 &                     0.477 &                 0.512 &                  0.475 &                                   0.547 &     0.566 \\
      fr &                  xlm-roberta-large &     0.559 &                     0.557 &                 0.544 &                  0.561 &                                   0.575 &     0.553 \\
      ge &            EleutherAI-gpt-neo-1.3B &     0.705 &                     0.700 &                 0.701 &              **0.796** &                                   0.719 &     0.717 \\
      ge &            EleutherAI-gpt-neo-125M &     0.593 &                     0.579 &                 0.649 &                  0.616 &                                   0.657 &     0.622 \\
      ge &       bert-base-multilingual-cased &     0.597 &                     0.681 &                 0.737 &                  0.709 &                                   0.641 &     0.730 \\
      ge & distilbert-base-multilingual-cased &     0.605 &                     0.664 &                 0.649 &                  0.654 &                                   0.727 &     0.688 \\
      ge &            facebook-mbart-large-50 &     0.709 &                     0.676 &                 0.669 &                  0.739 &                                   0.684 &     0.791 \\
      ge &                               gpt2 &     0.543 &                     0.591 &                 0.525 &                  0.699 &                                   0.699 &     0.675 \\
      ge &                  xlm-roberta-large &     0.711 &                     0.672 &                 0.717 &                  0.733 &                                   0.732 &     0.733 \\
      it &            EleutherAI-gpt-neo-1.3B &     0.650 &                     0.709 &                 0.717 &                  0.737 &                                   0.731 &     0.770 \\
      it &            EleutherAI-gpt-neo-125M &     0.526 &                     0.592 &                 0.574 &                  0.636 &                                   0.681 &     0.623 \\
      it &       bert-base-multilingual-cased &     0.583 &                     0.690 &                 0.686 &                  0.718 &                                   0.667 &     0.742 \\
      it & distilbert-base-multilingual-cased &     0.571 &                     0.617 &                 0.635 &                  0.713 &                                   0.608 &     0.757 \\
      it &            facebook-mbart-large-50 &     0.696 &                     0.717 &                 0.730 &                  0.720 &                                   0.748 &     0.778 \\
      it &                               gpt2 &     0.561 &                     0.588 &                 0.572 &                  0.637 &                                   0.640 &     0.627 \\
      it &                  xlm-roberta-large &     0.711 &                 **0.785** &                 0.755 &                  0.770 &                                   0.699 &     0.778 \\
      po &            EleutherAI-gpt-neo-1.3B &     0.595 &                     0.636 &                 0.705 &                  0.739 &                                   0.766 &     0.746 \\
      po &            EleutherAI-gpt-neo-125M &     0.558 &                     0.590 &                 0.592 &                  0.630 &                                   0.681 &     0.609 \\
      po &       bert-base-multilingual-cased &     0.624 &                     0.659 &                 0.715 &                  0.703 &                                   0.750 &     0.745 \\
      po & distilbert-base-multilingual-cased &     0.576 &                     0.655 &                 0.721 &                  0.727 &                                   0.684 &     0.730 \\
      po &            facebook-mbart-large-50 &     0.652 &                     0.692 &                 0.733 &                  0.763 &                                   0.796 & **0.801** \\
      po &                               gpt2 &     0.610 &                     0.593 &                 0.602 &                  0.632 &                                   0.678 &     0.688 \\
      po &                  xlm-roberta-large &     0.647 &                     0.692 &                 0.718 &                  0.747 &                                   0.775 &     0.779 \\
      ru &            EleutherAI-gpt-neo-1.3B & **0.727** &                     0.581 &                 0.625 &                  0.600 &                                   0.605 &     0.514 \\
      ru &            EleutherAI-gpt-neo-125M &     0.333 &                     0.250 &                 0.375 &                  0.347 &                                   0.308 &     0.190 \\
      ru &       bert-base-multilingual-cased &     0.500 &                     0.478 &                 0.561 &                  0.480 &                                   0.545 &     0.538 \\
      ru & distilbert-base-multilingual-cased &     0.410 &                     0.414 &                 0.567 &                  0.567 &                                   0.515 &     0.600 \\
      ru &            facebook-mbart-large-50 &     0.609 &                     0.600 &                 0.585 &                  0.633 &                                   0.672 &     0.685 \\
      ru &                               gpt2 &     0.231 &                     0.174 &                 0.300 &                  0.118 &                                   0.379 &     0.474 \\
      ru &                  xlm-roberta-large &     0.615 &                     0.673 &                 0.615 &                  0.625 &                                   0.633 &     0.636 \\
\bottomrule
\end{tabular}
