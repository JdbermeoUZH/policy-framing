dataset:
  data_dir: ['data', 'preprocessed']                                              # Relative path to directory with data

preprocessing:
  single_train_test_split_filepath: ['multilingual_train_test_ds.hf']
  data_split_to_use: 'train_and_dev'
  analysis_unit: 'title_and_first_paragraph'                                      # 'title', 'title_and_first_paragraph', 'title_and_5_sentences', 'title_and_10_sentences', 'title_and_first_sentence_each_paragraph', 'raw_text', 'all'
  n_folds: 3
  max_length_padding: 512

model:
  model_name: 'distilbert-base-multilingual-cased'                                                 # distilbert-base-multilingual-cased, bert-base-multilingual-cased
  fine_tune: True                                                                 # If False, will use a zero-shot pipeline
  load_in_8bit: False                                                             # Only supported at the moment for inference
  fp16: True

training:
  n_epochs: 20
  minibatch_size: 4
  gradient_accumulation_steps: 2
  best_metric_to_checkpoint: 'f1'
  warmup_ratio: 0.2
  dataloader_num_workers: 0

output:
  metrics_output_dir: ['tuning_results_llms','multilingual', 'truncated_512_tokens']
  file_prefix: 'multilingual_fit_trunc_512_tokens'



